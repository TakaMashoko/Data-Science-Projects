{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abb0ef6",
   "metadata": {},
   "source": [
    "# Homework 4 Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dab4efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:50:41.805017Z",
     "start_time": "2023-12-06T06:50:41.788904Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle \n",
    "from torch import nn, from_numpy\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2df50",
   "metadata": {},
   "source": [
    "## 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09a404d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:50:42.140747Z",
     "start_time": "2023-12-06T06:50:42.064086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the data, which is already divided into train and test sets\n",
    "X_train,X_test,y_train,y_test = pickle.load(open('fashion_mnist.p','rb'))\n",
    "\n",
    "# Converting to Torch tensors\n",
    "X_train = from_numpy(X_train)\n",
    "X_test = from_numpy(X_test)\n",
    "y_train = from_numpy(y_train)\n",
    "y_test = from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9353521c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:50:42.207249Z",
     "start_time": "2023-12-06T06:50:42.202255Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 10))\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5e35a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:51:14.358504Z",
     "start_time": "2023-12-06T06:50:42.749181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d667e330fd1e4304a0809695d6647ffd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample cross-entropy: 0.5445210337638855\n",
      "Out-of-sample accuracy: 0.8156\n",
      "In-sample cross-entropy: 0.4265199303627014\n",
      "Out-of-sample accuracy: 0.8385\n",
      "In-sample cross-entropy: 0.367085725069046\n",
      "Out-of-sample accuracy: 0.8489\n",
      "In-sample cross-entropy: 0.3718034029006958\n",
      "Out-of-sample accuracy: 0.8502\n",
      "In-sample cross-entropy: 0.34493282437324524\n",
      "Out-of-sample accuracy: 0.8518\n",
      "In-sample cross-entropy: 0.33230647444725037\n",
      "Out-of-sample accuracy: 0.857\n",
      "In-sample cross-entropy: 0.33205607533454895\n",
      "Out-of-sample accuracy: 0.851\n",
      "In-sample cross-entropy: 0.33839061856269836\n",
      "Out-of-sample accuracy: 0.8611\n",
      "In-sample cross-entropy: 0.35669049620628357\n",
      "Out-of-sample accuracy: 0.8619\n",
      "In-sample cross-entropy: 0.3262552320957184\n",
      "Out-of-sample accuracy: 0.8583\n",
      "In-sample cross-entropy: 0.3499659299850464\n",
      "Out-of-sample accuracy: 0.8562\n",
      "In-sample cross-entropy: 0.3276968002319336\n",
      "Out-of-sample accuracy: 0.8542\n",
      "In-sample cross-entropy: 0.356605589389801\n",
      "Out-of-sample accuracy: 0.8547\n",
      "In-sample cross-entropy: 0.3441137969493866\n",
      "Out-of-sample accuracy: 0.852\n",
      "In-sample cross-entropy: 0.3212197422981262\n",
      "Out-of-sample accuracy: 0.8608\n",
      "In-sample cross-entropy: 0.3015012741088867\n",
      "Out-of-sample accuracy: 0.8517\n",
      "In-sample cross-entropy: 0.31633269786834717\n",
      "Out-of-sample accuracy: 0.8632\n",
      "In-sample cross-entropy: 0.27458834648132324\n",
      "Out-of-sample accuracy: 0.8615\n",
      "In-sample cross-entropy: 0.332046777009964\n",
      "Out-of-sample accuracy: 0.8555\n",
      "In-sample cross-entropy: 0.31598302721977234\n",
      "Out-of-sample accuracy: 0.8596\n",
      "In-sample cross-entropy: 0.29502904415130615\n",
      "Out-of-sample accuracy: 0.8627\n",
      "In-sample cross-entropy: 0.2643398940563202\n",
      "Out-of-sample accuracy: 0.8592\n",
      "In-sample cross-entropy: 0.3243357837200165\n",
      "Out-of-sample accuracy: 0.8565\n",
      "In-sample cross-entropy: 0.27755895256996155\n",
      "Out-of-sample accuracy: 0.8581\n",
      "In-sample cross-entropy: 0.30650678277015686\n",
      "Out-of-sample accuracy: 0.8588\n",
      "In-sample cross-entropy: 0.27688068151474\n",
      "Out-of-sample accuracy: 0.8596\n",
      "In-sample cross-entropy: 0.2582443952560425\n",
      "Out-of-sample accuracy: 0.8577\n",
      "In-sample cross-entropy: 0.2641787827014923\n",
      "Out-of-sample accuracy: 0.861\n",
      "In-sample cross-entropy: 0.2622658312320709\n",
      "Out-of-sample accuracy: 0.8572\n",
      "In-sample cross-entropy: 0.301102876663208\n",
      "Out-of-sample accuracy: 0.8583\n",
      "In-sample cross-entropy: 0.2761416733264923\n",
      "Out-of-sample accuracy: 0.8648\n",
      "In-sample cross-entropy: 0.2571737468242645\n",
      "Out-of-sample accuracy: 0.8612\n",
      "In-sample cross-entropy: 0.2913798689842224\n",
      "Out-of-sample accuracy: 0.8581\n",
      "In-sample cross-entropy: 0.28643998503685\n",
      "Out-of-sample accuracy: 0.8562\n",
      "In-sample cross-entropy: 0.24212077260017395\n",
      "Out-of-sample accuracy: 0.8621\n",
      "In-sample cross-entropy: 0.2852824032306671\n",
      "Out-of-sample accuracy: 0.8557\n",
      "In-sample cross-entropy: 0.2653156518936157\n",
      "Out-of-sample accuracy: 0.8617\n",
      "In-sample cross-entropy: 0.2678205668926239\n",
      "Out-of-sample accuracy: 0.861\n",
      "In-sample cross-entropy: 0.2566153109073639\n",
      "Out-of-sample accuracy: 0.8647\n",
      "In-sample cross-entropy: 0.27996841073036194\n",
      "Out-of-sample accuracy: 0.8628\n",
      "In-sample cross-entropy: 0.27959880232810974\n",
      "Out-of-sample accuracy: 0.8603\n",
      "In-sample cross-entropy: 0.38460394740104675\n",
      "Out-of-sample accuracy: 0.8482\n",
      "In-sample cross-entropy: 0.2859751284122467\n",
      "Out-of-sample accuracy: 0.8563\n",
      "In-sample cross-entropy: 0.2656223475933075\n",
      "Out-of-sample accuracy: 0.8552\n",
      "In-sample cross-entropy: 0.26626551151275635\n",
      "Out-of-sample accuracy: 0.8613\n",
      "In-sample cross-entropy: 0.2839467227458954\n",
      "Out-of-sample accuracy: 0.8603\n",
      "In-sample cross-entropy: 0.2912353575229645\n",
      "Out-of-sample accuracy: 0.854\n",
      "In-sample cross-entropy: 0.28736448287963867\n",
      "Out-of-sample accuracy: 0.8539\n",
      "In-sample cross-entropy: 0.2888779938220978\n",
      "Out-of-sample accuracy: 0.8515\n",
      "In-sample cross-entropy: 0.2735377550125122\n",
      "Out-of-sample accuracy: 0.8557\n",
      "In-sample cross-entropy: 0.2846203148365021\n",
      "Out-of-sample accuracy: 0.8592\n",
      "In-sample cross-entropy: 0.2738627791404724\n",
      "Out-of-sample accuracy: 0.8601\n",
      "In-sample cross-entropy: 0.3230953812599182\n",
      "Out-of-sample accuracy: 0.8582\n",
      "In-sample cross-entropy: 0.31020358204841614\n",
      "Out-of-sample accuracy: 0.8486\n",
      "In-sample cross-entropy: 0.2630162239074707\n",
      "Out-of-sample accuracy: 0.8569\n",
      "In-sample cross-entropy: 0.3069356083869934\n",
      "Out-of-sample accuracy: 0.8558\n",
      "In-sample cross-entropy: 0.3018344044685364\n",
      "Out-of-sample accuracy: 0.8487\n",
      "In-sample cross-entropy: 0.30442047119140625\n",
      "Out-of-sample accuracy: 0.8537\n",
      "In-sample cross-entropy: 0.2957903742790222\n",
      "Out-of-sample accuracy: 0.8574\n",
      "In-sample cross-entropy: 0.2762361466884613\n",
      "Out-of-sample accuracy: 0.8564\n",
      "In-sample cross-entropy: 0.30700844526290894\n",
      "Out-of-sample accuracy: 0.8457\n",
      "In-sample cross-entropy: 0.27844807505607605\n",
      "Out-of-sample accuracy: 0.8544\n",
      "In-sample cross-entropy: 0.29240599274635315\n",
      "Out-of-sample accuracy: 0.852\n",
      "In-sample cross-entropy: 0.3507554531097412\n",
      "Out-of-sample accuracy: 0.851\n",
      "In-sample cross-entropy: 0.29782289266586304\n",
      "Out-of-sample accuracy: 0.8444\n",
      "In-sample cross-entropy: 0.2886534631252289\n",
      "Out-of-sample accuracy: 0.8539\n",
      "In-sample cross-entropy: 0.3546381890773773\n",
      "Out-of-sample accuracy: 0.8457\n",
      "In-sample cross-entropy: 0.2981295585632324\n",
      "Out-of-sample accuracy: 0.8512\n",
      "In-sample cross-entropy: 0.2866577208042145\n",
      "Out-of-sample accuracy: 0.8495\n",
      "In-sample cross-entropy: 0.29032960534095764\n",
      "Out-of-sample accuracy: 0.8478\n",
      "In-sample cross-entropy: 0.28007858991622925\n",
      "Out-of-sample accuracy: 0.8488\n",
      "In-sample cross-entropy: 0.309639036655426\n",
      "Out-of-sample accuracy: 0.8419\n",
      "In-sample cross-entropy: 0.3135479688644409\n",
      "Out-of-sample accuracy: 0.8463\n",
      "In-sample cross-entropy: 0.36750826239585876\n",
      "Out-of-sample accuracy: 0.8466\n",
      "In-sample cross-entropy: 0.2898986339569092\n",
      "Out-of-sample accuracy: 0.8495\n",
      "In-sample cross-entropy: 0.34372296929359436\n",
      "Out-of-sample accuracy: 0.8499\n",
      "In-sample cross-entropy: 0.3024430274963379\n",
      "Out-of-sample accuracy: 0.8468\n",
      "In-sample cross-entropy: 0.2987569570541382\n",
      "Out-of-sample accuracy: 0.8453\n",
      "In-sample cross-entropy: 0.3748430907726288\n",
      "Out-of-sample accuracy: 0.8388\n",
      "In-sample cross-entropy: 0.29097720980644226\n",
      "Out-of-sample accuracy: 0.8497\n",
      "In-sample cross-entropy: 0.3844398558139801\n",
      "Out-of-sample accuracy: 0.8413\n",
      "In-sample cross-entropy: 0.2815355062484741\n",
      "Out-of-sample accuracy: 0.8418\n",
      "In-sample cross-entropy: 0.3509249985218048\n",
      "Out-of-sample accuracy: 0.8448\n",
      "In-sample cross-entropy: 0.29388946294784546\n",
      "Out-of-sample accuracy: 0.8474\n",
      "In-sample cross-entropy: 0.29730138182640076\n",
      "Out-of-sample accuracy: 0.8474\n",
      "In-sample cross-entropy: 0.29217347502708435\n",
      "Out-of-sample accuracy: 0.839\n",
      "In-sample cross-entropy: 0.2999376654624939\n",
      "Out-of-sample accuracy: 0.8483\n",
      "In-sample cross-entropy: 0.37535637617111206\n",
      "Out-of-sample accuracy: 0.8443\n",
      "In-sample cross-entropy: 0.3308250904083252\n",
      "Out-of-sample accuracy: 0.8469\n",
      "In-sample cross-entropy: 0.29473796486854553\n",
      "Out-of-sample accuracy: 0.8455\n",
      "In-sample cross-entropy: 0.28510618209838867\n",
      "Out-of-sample accuracy: 0.8453\n",
      "In-sample cross-entropy: 0.37436866760253906\n",
      "Out-of-sample accuracy: 0.8452\n",
      "In-sample cross-entropy: 0.3048437237739563\n",
      "Out-of-sample accuracy: 0.8513\n",
      "In-sample cross-entropy: 0.3314690887928009\n",
      "Out-of-sample accuracy: 0.8482\n",
      "In-sample cross-entropy: 0.3033013343811035\n",
      "Out-of-sample accuracy: 0.8473\n",
      "In-sample cross-entropy: 0.28833630681037903\n",
      "Out-of-sample accuracy: 0.8501\n",
      "In-sample cross-entropy: 0.32912498712539673\n",
      "Out-of-sample accuracy: 0.8482\n",
      "In-sample cross-entropy: 0.29334956407546997\n",
      "Out-of-sample accuracy: 0.8452\n",
      "In-sample cross-entropy: 0.28327396512031555\n",
      "Out-of-sample accuracy: 0.8482\n",
      "In-sample cross-entropy: 0.30800938606262207\n",
      "Out-of-sample accuracy: 0.8486\n"
     ]
    }
   ],
   "source": [
    "# Stochastic gradient descent\n",
    "batch_size = 128\n",
    "\n",
    "for cycle in tqdm(range(100)):\n",
    "    \n",
    "    for batch in range(int(60000/batch_size)):\n",
    "        # ForwardProp\n",
    "        y_pred = model(X_train[batch*batch_size:(batch+1)*batch_size]) \n",
    "        loss = loss_function(y_pred, y_train[batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "        # BackwardProp\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "    # Printing in-sample and out-of-sample accuracy    \n",
    "    print('In-sample cross-entropy: ' + str(loss.item()))\n",
    "    y_pred = model(X_test)\n",
    "    print('Out-of-sample accuracy: ' + str((y_pred.argmax(1) == y_test).sum().item() / 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e5b6a90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:51:14.364685Z",
     "start_time": "2023-12-06T06:51:14.359763Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(32, 10))\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1c48d56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:51:49.804556Z",
     "start_time": "2023-12-06T06:51:14.366512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdee224fb3cf476ca162d2010815f6c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample cross-entropy: 0.5230948328971863\n",
      "Out-of-sample accuracy: 0.8301\n",
      "In-sample cross-entropy: 0.4547313153743744\n",
      "Out-of-sample accuracy: 0.8405\n",
      "In-sample cross-entropy: 0.4867345094680786\n",
      "Out-of-sample accuracy: 0.8511\n",
      "In-sample cross-entropy: 0.34561070799827576\n",
      "Out-of-sample accuracy: 0.8658\n",
      "In-sample cross-entropy: 0.4048910140991211\n",
      "Out-of-sample accuracy: 0.8647\n",
      "In-sample cross-entropy: 0.3274666368961334\n",
      "Out-of-sample accuracy: 0.8541\n",
      "In-sample cross-entropy: 0.3240302801132202\n",
      "Out-of-sample accuracy: 0.8688\n",
      "In-sample cross-entropy: 0.3386389911174774\n",
      "Out-of-sample accuracy: 0.8646\n",
      "In-sample cross-entropy: 0.307913213968277\n",
      "Out-of-sample accuracy: 0.8711\n",
      "In-sample cross-entropy: 0.3099919259548187\n",
      "Out-of-sample accuracy: 0.8757\n",
      "In-sample cross-entropy: 0.28839942812919617\n",
      "Out-of-sample accuracy: 0.8693\n",
      "In-sample cross-entropy: 0.29601895809173584\n",
      "Out-of-sample accuracy: 0.8582\n",
      "In-sample cross-entropy: 0.25698572397232056\n",
      "Out-of-sample accuracy: 0.8637\n",
      "In-sample cross-entropy: 0.31593307852745056\n",
      "Out-of-sample accuracy: 0.8782\n",
      "In-sample cross-entropy: 0.29960328340530396\n",
      "Out-of-sample accuracy: 0.8697\n",
      "In-sample cross-entropy: 0.2997002601623535\n",
      "Out-of-sample accuracy: 0.8749\n",
      "In-sample cross-entropy: 0.2638816237449646\n",
      "Out-of-sample accuracy: 0.8753\n",
      "In-sample cross-entropy: 0.28149089217185974\n",
      "Out-of-sample accuracy: 0.8708\n",
      "In-sample cross-entropy: 0.2842727303504944\n",
      "Out-of-sample accuracy: 0.8786\n",
      "In-sample cross-entropy: 0.30449339747428894\n",
      "Out-of-sample accuracy: 0.8831\n",
      "In-sample cross-entropy: 0.29167500138282776\n",
      "Out-of-sample accuracy: 0.8785\n",
      "In-sample cross-entropy: 0.2944977581501007\n",
      "Out-of-sample accuracy: 0.8807\n",
      "In-sample cross-entropy: 0.24105392396450043\n",
      "Out-of-sample accuracy: 0.8802\n",
      "In-sample cross-entropy: 0.22855991125106812\n",
      "Out-of-sample accuracy: 0.8855\n",
      "In-sample cross-entropy: 0.21258600056171417\n",
      "Out-of-sample accuracy: 0.8802\n",
      "In-sample cross-entropy: 0.2630595266819\n",
      "Out-of-sample accuracy: 0.8814\n",
      "In-sample cross-entropy: 0.2398475855588913\n",
      "Out-of-sample accuracy: 0.8831\n",
      "In-sample cross-entropy: 0.19306842982769012\n",
      "Out-of-sample accuracy: 0.8849\n",
      "In-sample cross-entropy: 0.21935798227787018\n",
      "Out-of-sample accuracy: 0.8737\n",
      "In-sample cross-entropy: 0.19988684356212616\n",
      "Out-of-sample accuracy: 0.8891\n",
      "In-sample cross-entropy: 0.1795942485332489\n",
      "Out-of-sample accuracy: 0.8784\n",
      "In-sample cross-entropy: 0.24289020895957947\n",
      "Out-of-sample accuracy: 0.885\n",
      "In-sample cross-entropy: 0.1992039829492569\n",
      "Out-of-sample accuracy: 0.8842\n",
      "In-sample cross-entropy: 0.20735855400562286\n",
      "Out-of-sample accuracy: 0.8825\n",
      "In-sample cross-entropy: 0.18828831613063812\n",
      "Out-of-sample accuracy: 0.8822\n",
      "In-sample cross-entropy: 0.19881638884544373\n",
      "Out-of-sample accuracy: 0.8836\n",
      "In-sample cross-entropy: 0.18876765668392181\n",
      "Out-of-sample accuracy: 0.8861\n",
      "In-sample cross-entropy: 0.19935037195682526\n",
      "Out-of-sample accuracy: 0.8835\n",
      "In-sample cross-entropy: 0.22173546254634857\n",
      "Out-of-sample accuracy: 0.8803\n",
      "In-sample cross-entropy: 0.1528070867061615\n",
      "Out-of-sample accuracy: 0.8839\n",
      "In-sample cross-entropy: 0.1595984250307083\n",
      "Out-of-sample accuracy: 0.8794\n",
      "In-sample cross-entropy: 0.27718791365623474\n",
      "Out-of-sample accuracy: 0.8787\n",
      "In-sample cross-entropy: 0.17105287313461304\n",
      "Out-of-sample accuracy: 0.8819\n",
      "In-sample cross-entropy: 0.19116279482841492\n",
      "Out-of-sample accuracy: 0.8797\n",
      "In-sample cross-entropy: 0.17740213871002197\n",
      "Out-of-sample accuracy: 0.8775\n",
      "In-sample cross-entropy: 0.1527833342552185\n",
      "Out-of-sample accuracy: 0.8809\n",
      "In-sample cross-entropy: 0.16063453257083893\n",
      "Out-of-sample accuracy: 0.8833\n",
      "In-sample cross-entropy: 0.2016122043132782\n",
      "Out-of-sample accuracy: 0.8804\n",
      "In-sample cross-entropy: 0.16710829734802246\n",
      "Out-of-sample accuracy: 0.8768\n",
      "In-sample cross-entropy: 0.19233155250549316\n",
      "Out-of-sample accuracy: 0.8808\n",
      "In-sample cross-entropy: 0.16973291337490082\n",
      "Out-of-sample accuracy: 0.8837\n",
      "In-sample cross-entropy: 0.1797623336315155\n",
      "Out-of-sample accuracy: 0.8806\n",
      "In-sample cross-entropy: 0.1863536387681961\n",
      "Out-of-sample accuracy: 0.8778\n",
      "In-sample cross-entropy: 0.196243017911911\n",
      "Out-of-sample accuracy: 0.8795\n",
      "In-sample cross-entropy: 0.24819448590278625\n",
      "Out-of-sample accuracy: 0.8782\n",
      "In-sample cross-entropy: 0.1760970652103424\n",
      "Out-of-sample accuracy: 0.8773\n",
      "In-sample cross-entropy: 0.1484970897436142\n",
      "Out-of-sample accuracy: 0.8806\n",
      "In-sample cross-entropy: 0.14630891382694244\n",
      "Out-of-sample accuracy: 0.8812\n",
      "In-sample cross-entropy: 0.13738013803958893\n",
      "Out-of-sample accuracy: 0.8807\n",
      "In-sample cross-entropy: 0.1714007407426834\n",
      "Out-of-sample accuracy: 0.8797\n",
      "In-sample cross-entropy: 0.1709604412317276\n",
      "Out-of-sample accuracy: 0.8815\n",
      "In-sample cross-entropy: 0.11741748452186584\n",
      "Out-of-sample accuracy: 0.8819\n",
      "In-sample cross-entropy: 0.14154568314552307\n",
      "Out-of-sample accuracy: 0.8826\n",
      "In-sample cross-entropy: 0.20367993414402008\n",
      "Out-of-sample accuracy: 0.8768\n",
      "In-sample cross-entropy: 0.12928587198257446\n",
      "Out-of-sample accuracy: 0.8769\n",
      "In-sample cross-entropy: 0.19984105229377747\n",
      "Out-of-sample accuracy: 0.8759\n",
      "In-sample cross-entropy: 0.17599911987781525\n",
      "Out-of-sample accuracy: 0.8759\n",
      "In-sample cross-entropy: 0.1668705940246582\n",
      "Out-of-sample accuracy: 0.8733\n",
      "In-sample cross-entropy: 0.2090810090303421\n",
      "Out-of-sample accuracy: 0.8807\n",
      "In-sample cross-entropy: 0.1492370069026947\n",
      "Out-of-sample accuracy: 0.8775\n",
      "In-sample cross-entropy: 0.19191068410873413\n",
      "Out-of-sample accuracy: 0.8749\n",
      "In-sample cross-entropy: 0.18112115561962128\n",
      "Out-of-sample accuracy: 0.8755\n",
      "In-sample cross-entropy: 0.11435779929161072\n",
      "Out-of-sample accuracy: 0.8769\n",
      "In-sample cross-entropy: 0.09378054738044739\n",
      "Out-of-sample accuracy: 0.8813\n",
      "In-sample cross-entropy: 0.12031703442335129\n",
      "Out-of-sample accuracy: 0.8788\n",
      "In-sample cross-entropy: 0.17044222354888916\n",
      "Out-of-sample accuracy: 0.8752\n",
      "In-sample cross-entropy: 0.13126957416534424\n",
      "Out-of-sample accuracy: 0.8796\n",
      "In-sample cross-entropy: 0.0944836214184761\n",
      "Out-of-sample accuracy: 0.8796\n",
      "In-sample cross-entropy: 0.15186196565628052\n",
      "Out-of-sample accuracy: 0.88\n",
      "In-sample cross-entropy: 0.13882823288440704\n",
      "Out-of-sample accuracy: 0.8786\n",
      "In-sample cross-entropy: 0.11029066890478134\n",
      "Out-of-sample accuracy: 0.8793\n",
      "In-sample cross-entropy: 0.1302953064441681\n",
      "Out-of-sample accuracy: 0.8804\n",
      "In-sample cross-entropy: 0.12317894399166107\n",
      "Out-of-sample accuracy: 0.8793\n",
      "In-sample cross-entropy: 0.1437290459871292\n",
      "Out-of-sample accuracy: 0.8778\n",
      "In-sample cross-entropy: 0.15670964121818542\n",
      "Out-of-sample accuracy: 0.8765\n",
      "In-sample cross-entropy: 0.2362818568944931\n",
      "Out-of-sample accuracy: 0.8794\n",
      "In-sample cross-entropy: 0.11434043943881989\n",
      "Out-of-sample accuracy: 0.8773\n",
      "In-sample cross-entropy: 0.1502353549003601\n",
      "Out-of-sample accuracy: 0.8741\n",
      "In-sample cross-entropy: 0.07743177562952042\n",
      "Out-of-sample accuracy: 0.8775\n",
      "In-sample cross-entropy: 0.1436546891927719\n",
      "Out-of-sample accuracy: 0.8816\n",
      "In-sample cross-entropy: 0.1090276688337326\n",
      "Out-of-sample accuracy: 0.8791\n",
      "In-sample cross-entropy: 0.1030559241771698\n",
      "Out-of-sample accuracy: 0.881\n",
      "In-sample cross-entropy: 0.09115860611200333\n",
      "Out-of-sample accuracy: 0.8761\n",
      "In-sample cross-entropy: 0.08911623805761337\n",
      "Out-of-sample accuracy: 0.8732\n",
      "In-sample cross-entropy: 0.09419450163841248\n",
      "Out-of-sample accuracy: 0.8768\n",
      "In-sample cross-entropy: 0.13108859956264496\n",
      "Out-of-sample accuracy: 0.8778\n",
      "In-sample cross-entropy: 0.09551561623811722\n",
      "Out-of-sample accuracy: 0.8751\n",
      "In-sample cross-entropy: 0.08297532796859741\n",
      "Out-of-sample accuracy: 0.8817\n",
      "In-sample cross-entropy: 0.08229676634073257\n",
      "Out-of-sample accuracy: 0.8751\n",
      "In-sample cross-entropy: 0.09544211626052856\n",
      "Out-of-sample accuracy: 0.8801\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for cycle in tqdm(range(100)):\n",
    "    \n",
    "    for batch in range(int(60000/batch_size)):\n",
    "        # ForwardProp\n",
    "        y_pred = model(X_train[batch*batch_size:(batch+1)*batch_size]) \n",
    "        loss = loss_function(y_pred, y_train[batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "        # BackwardProp\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "    # Printing in-sample and out-of-sample accuracy    \n",
    "    print('In-sample cross-entropy: ' + str(loss.item()))\n",
    "    y_pred = model(X_test)\n",
    "    print('Out-of-sample accuracy: ' + str((y_pred.argmax(1) == y_test).sum().item() / 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c6104",
   "metadata": {},
   "source": [
    "## 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de53112e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:52:16.399150Z",
     "start_time": "2023-12-06T06:52:16.242726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Re-Loading the data\n",
    "X_train,X_test,y_train,y_test = pickle.load(open('fashion_mnist.p','rb'))\n",
    "\n",
    "# Re-shaping the data\n",
    "X_train = np.reshape(X_train, (60000,1,28,28))\n",
    "X_test  = np.reshape(X_test, (10000,1,28,28))\n",
    "\n",
    "# Converting to Torch tensors\n",
    "X_train = from_numpy(X_train)\n",
    "X_test = from_numpy(X_test)\n",
    "y_train = from_numpy(y_train)\n",
    "y_test = from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20810dfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:52:16.406988Z",
     "start_time": "2023-12-06T06:52:16.400559Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Conv2d(1,40,6),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(40*23*23,10))\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8939545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:54:39.287297Z",
     "start_time": "2023-12-06T06:52:16.533501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c6b54d79a09422e87a6bb5e68e3b595"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample cross-entropy: 1.1508057117462158\n",
      "Out-of-sample accuracy: 0.8545\n",
      "In-sample cross-entropy: 0.42699775099754333\n",
      "Out-of-sample accuracy: 0.8653\n",
      "In-sample cross-entropy: 0.2663837969303131\n",
      "Out-of-sample accuracy: 0.8684\n",
      "In-sample cross-entropy: 0.1936825066804886\n",
      "Out-of-sample accuracy: 0.8688\n",
      "In-sample cross-entropy: 0.1704409271478653\n",
      "Out-of-sample accuracy: 0.8689\n",
      "In-sample cross-entropy: 0.0827985405921936\n",
      "Out-of-sample accuracy: 0.8699\n",
      "In-sample cross-entropy: 0.1611524224281311\n",
      "Out-of-sample accuracy: 0.8641\n",
      "In-sample cross-entropy: 0.10011878609657288\n",
      "Out-of-sample accuracy: 0.8682\n",
      "In-sample cross-entropy: 0.08255527913570404\n",
      "Out-of-sample accuracy: 0.8692\n",
      "In-sample cross-entropy: 0.07360697537660599\n",
      "Out-of-sample accuracy: 0.8643\n",
      "In-sample cross-entropy: 0.07937152683734894\n",
      "Out-of-sample accuracy: 0.871\n",
      "In-sample cross-entropy: 0.1309375762939453\n",
      "Out-of-sample accuracy: 0.8639\n",
      "In-sample cross-entropy: 0.051972150802612305\n",
      "Out-of-sample accuracy: 0.8653\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# BackwardProp\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad() \n\u001B[0;32m---> 12\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \n\u001B[1;32m     13\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep() \n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Printing in-sample and out-of-sample accuracy    \u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlba/lib/python3.8/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlba/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for cycle in tqdm(range(100)):\n",
    "    \n",
    "    for batch in range(int(60000/batch_size)):\n",
    "        # ForwardProp\n",
    "        y_pred = model(X_train[batch*batch_size:(batch+1)*batch_size]) \n",
    "        loss = loss_function(y_pred, y_train[batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "        # BackwardProp\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "    # Printing in-sample and out-of-sample accuracy    \n",
    "    print('In-sample cross-entropy: ' + str(loss.item()))\n",
    "    y_pred = model(X_test)\n",
    "    print('Out-of-sample accuracy: ' + str((y_pred.argmax(1) == y_test).sum().item() / 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aada70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:55:12.412806Z",
     "start_time": "2023-12-06T06:55:12.393455Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Conv2d(1,32,5),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(32*24*24,32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(32,10))\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0a0e8d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:59:06.485076Z",
     "start_time": "2023-12-06T06:55:12.797446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81d0c383777441d69872579e9c29dbce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample cross-entropy: 1.5321178436279297\n",
      "Out-of-sample accuracy: 0.4418\n",
      "In-sample cross-entropy: 1.2504676580429077\n",
      "Out-of-sample accuracy: 0.5106\n",
      "In-sample cross-entropy: 1.1926028728485107\n",
      "Out-of-sample accuracy: 0.5333\n",
      "In-sample cross-entropy: 1.0065008401870728\n",
      "Out-of-sample accuracy: 0.5637\n",
      "In-sample cross-entropy: 0.9695659279823303\n",
      "Out-of-sample accuracy: 0.5697\n",
      "In-sample cross-entropy: 0.8836402893066406\n",
      "Out-of-sample accuracy: 0.5749\n",
      "In-sample cross-entropy: 0.8513344526290894\n",
      "Out-of-sample accuracy: 0.5774\n",
      "In-sample cross-entropy: 0.8491548895835876\n",
      "Out-of-sample accuracy: 0.5837\n",
      "In-sample cross-entropy: 0.791728675365448\n",
      "Out-of-sample accuracy: 0.6366\n",
      "In-sample cross-entropy: 0.5651496052742004\n",
      "Out-of-sample accuracy: 0.7482\n",
      "In-sample cross-entropy: 0.5251263976097107\n",
      "Out-of-sample accuracy: 0.827\n",
      "In-sample cross-entropy: 0.26563867926597595\n",
      "Out-of-sample accuracy: 0.8625\n",
      "In-sample cross-entropy: 0.2645862102508545\n",
      "Out-of-sample accuracy: 0.8743\n",
      "In-sample cross-entropy: 0.20269270241260529\n",
      "Out-of-sample accuracy: 0.8774\n",
      "In-sample cross-entropy: 0.19357576966285706\n",
      "Out-of-sample accuracy: 0.872\n",
      "In-sample cross-entropy: 0.13771319389343262\n",
      "Out-of-sample accuracy: 0.8777\n",
      "In-sample cross-entropy: 0.12436377257108688\n",
      "Out-of-sample accuracy: 0.8778\n",
      "In-sample cross-entropy: 0.11571194976568222\n",
      "Out-of-sample accuracy: 0.8797\n",
      "In-sample cross-entropy: 0.08571743220090866\n",
      "Out-of-sample accuracy: 0.8799\n",
      "In-sample cross-entropy: 0.09189514815807343\n",
      "Out-of-sample accuracy: 0.8773\n",
      "In-sample cross-entropy: 0.11673620343208313\n",
      "Out-of-sample accuracy: 0.8805\n",
      "In-sample cross-entropy: 0.06113150343298912\n",
      "Out-of-sample accuracy: 0.8798\n",
      "In-sample cross-entropy: 0.08686328679323196\n",
      "Out-of-sample accuracy: 0.8837\n",
      "In-sample cross-entropy: 0.06844007223844528\n",
      "Out-of-sample accuracy: 0.8761\n",
      "In-sample cross-entropy: 0.10428684204816818\n",
      "Out-of-sample accuracy: 0.8798\n",
      "In-sample cross-entropy: 0.08027850836515427\n",
      "Out-of-sample accuracy: 0.882\n",
      "In-sample cross-entropy: 0.05447527766227722\n",
      "Out-of-sample accuracy: 0.8787\n",
      "In-sample cross-entropy: 0.07932428270578384\n",
      "Out-of-sample accuracy: 0.8759\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad() \n\u001B[1;32m     12\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward() \n\u001B[0;32m---> 13\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Printing in-sample and out-of-sample accuracy    \u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIn-sample cross-entropy: \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(loss\u001B[38;5;241m.\u001B[39mitem()))\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlba/lib/python3.8/site-packages/torch/optim/optimizer.py:373\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    368\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    369\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    370\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    371\u001B[0m             )\n\u001B[0;32m--> 373\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlba/lib/python3.8/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlba/lib/python3.8/site-packages/torch/optim/adam.py:163\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    152\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    155\u001B[0m         group,\n\u001B[1;32m    156\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    161\u001B[0m         state_steps)\n\u001B[0;32m--> 163\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlba/lib/python3.8/site-packages/torch/optim/adam.py:311\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    309\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 311\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlba/lib/python3.8/site-packages/torch/optim/adam.py:432\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    430\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    431\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 432\u001B[0m         denom \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbias_correction2_sqrt\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    434\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[1;32m    436\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for cycle in tqdm(range(100)):\n",
    "    \n",
    "    for batch in range(int(60000/batch_size)):\n",
    "        # ForwardProp\n",
    "        y_pred = model(X_train[batch*batch_size:(batch+1)*batch_size]) \n",
    "        loss = loss_function(y_pred, y_train[batch*batch_size:(batch+1)*batch_size])\n",
    "\n",
    "        # BackwardProp\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "    # Printing in-sample and out-of-sample accuracy    \n",
    "    print('In-sample cross-entropy: ' + str(loss.item()))\n",
    "    y_pred = model(X_test)\n",
    "    print('Out-of-sample accuracy: ' + str((y_pred.argmax(1) == y_test).sum().item() / 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c8f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:44:19.156233Z",
     "start_time": "2023-12-06T06:44:19.155961Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
